
# *R*obust *L*ocal *E*xplainers
As the machine learning community creates increasingly complex models and pervases areas of societal impact, we are struck with the problem of understanding decisions made by machine learning models without sacrificing their accuracy.

This repo contains some experiments with the concept of a local explainer, as presented by Ribeiro et. al in 
*["Why Should I Trust You":Explainining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)*. We explore the role of locality in the results with some toy examples, attempting to help answering the question: *How can we be sure we can trust a local explainer?*
 
 